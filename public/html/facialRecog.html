<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Facial Recognition with OpenCV.js</title>
  <script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>
<<<<<<< HEAD
  <link rel="stylesheet" href="../css/style.css">
=======
>>>>>>> fb1ebe4ff84ee7a0da4a8d5a4a12eb07f93e450d
</head>
<style>html, body {
  height: 100%;
  margin: 0;
  display: flex;
  justify-content: center;
  align-items: center;
  background-color: #f0f0f0;
}

/* Flex container for centering the video */
.center-container {
  display: flex;
  justify-content: center;
  align-items: center;
  height: 100%;
}

/* Optional styling for the video */
video {
  border: 2px solid #333;
  border-radius: 8px;
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
}
</style>
<body>
<<<<<<< HEAD
  <img src="../images/OcbcLogo.png" alt="Logo" class="logo">
=======
>>>>>>> fb1ebe4ff84ee7a0da4a8d5a4a12eb07f93e450d
  <video id="video" width="640" height="480" autoplay></video>
  <canvas id="canvas" width="640" height="480" style="display:none;"></canvas>
  <button id="capture">Capture</button>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const context = canvas.getContext('2d');
    let faceCascade;

    // Wait until OpenCV.js is ready
    function onOpenCvReady() {
        console.log('OpenCV.js is ready!');
        loadCascade();
    }

    // Load Haar Cascade for face detection
    async function loadCascade() {
        const response = await fetch('../../opencv_data_haarcascades_haarcascade_frontalface_default.xml at master Â· kipr_opencv_files');
        const data = await response.text();
        faceCascade = new cv.CascadeClassifier();
        faceCascade.load(data);
    }

    // Access the webcam
    navigator.mediaDevices.getUserMedia({ video: true })
        .then((stream) => {
        video.srcObject = stream;
        })
        .catch(console.error);

    // Detect faces every 100ms
    setInterval(detectFace, 100);

    function detectFace() {
        if (!faceCascade) return;

        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        const src = cv.imread(canvas);
        const gray = new cv.Mat();
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

        const faces = new cv.RectVector();
        faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0);

        for (let i = 0; i < faces.size(); i++) {
        const face = faces.get(i);
        cv.rectangle(src, face, [255, 0, 0, 255], 2);
        }

        cv.imshow('canvas', src);
        src.delete();
        gray.delete();
        faces.delete();
    }

    // Capture and send image to backend
    document.getElementById('capture').addEventListener('click', () => {
        const dataURL = canvas.toDataURL('image/png');

        fetch('/login', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ image: dataURL }),
        })
        .then((response) => response.json())
        .then((data) => alert(data.success ? 'Login successful' : 'Face not recognized'))
        .catch(console.error);
    });
  </script>
</body>
</html>
